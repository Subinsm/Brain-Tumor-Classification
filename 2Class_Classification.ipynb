{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "import pickle\n",
    "import cv2\n",
    "import time\n",
    "import glob\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop \n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout, Conv3D, MaxPooling3D, Input, concatenate\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(r\"/content/drive/My Drive/Upenn_Data/training_data.csv\") #refer .csv for cross-validation implementation\n",
    "df_val = pd.read_csv(r\"/content/drive/My Drive/Upenn_Data/validation_data.csv\")\n",
    "column = \"CPM_RadPath_2019_ID\"\n",
    "class_name = \"class\"\n",
    "input_path = r'/content/drive/My Drive/UPenn_Data/miccai2019-data/CPM-RadPath_2019_Training_Data/Radiology'\n",
    "flair_format = \"_flair.nii.gz\"\n",
    "t1_format = \"_t1.nii.gz\"\n",
    "t1ce_format = \"_t1ce.nii.gz\"\n",
    "t2_format = \"_t2.nii.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_flair = []\n",
    "val_flair = []\n",
    "train_t1 = []\n",
    "val_t1 = []\n",
    "train_t1ce = []\n",
    "val_t1ce = []\n",
    "train_t2 = []\n",
    "val_t2 = []\n",
    "class_train = []\n",
    "class_val = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,208):\n",
    "    data_path = df_train[column][i]\n",
    "    \n",
    "    flair_path = os.path.join(input_path,data_path,data_path+flair_format)\n",
    "    flair_image = nib.load(flair_path)\n",
    "    flair = flair_image.get_data()\n",
    "    flair[flair!=0] = ((((flair[flair!=0] - np.mean(flair[flair!=0]))/ np.std(flair[flair!=0]))+ 10)* 100).astype(dtype=np.int16)\n",
    "    train_flair.append(flair)\n",
    "    \n",
    "    t1_path = os.path.join(input_path,data_path,data_path+t1_format)\n",
    "    t1_image = nib.load(t1_path)\n",
    "    t1 = t1_image.get_data()\n",
    "    t1[t1!=0] = ((((t1[t1!=0] - np.mean(t1[t1!=0]))/ np.std(t1[t1!=0]))+ 10)* 100).astype(dtype=np.int16)\n",
    "    train_t1.append(t1)\n",
    "    \n",
    "    t1ce_path = os.path.join(input_path,data_path,data_path+t1ce_format)\n",
    "    t1ce_image = nib.load(t1ce_path)\n",
    "    t1ce = t1ce_image.get_data()\n",
    "    t1ce[t1ce!=0] = ((((t1ce[t1ce!=0] - np.mean(t1ce[t1ce!=0]))/ np.std(t1ce[t1ce!=0]))+ 10)* 100).astype(dtype=np.int16)\n",
    "    train_t1ce.append(t1ce)\n",
    "    \n",
    "    t2_path = os.path.join(input_path,data_path,data_path+t2_format)\n",
    "    t2_image = nib.load(t2_path)\n",
    "    t2 = t2_image.get_data()\n",
    "    t2[t2!=0] = ((((t2[t2!=0] - np.mean(t2[t2!=0]))/ np.std(t2[t2!=0]))+ 10)* 100).astype(dtype=np.int16)\n",
    "    train_t2.append(t2)\n",
    "    \n",
    "    train_class.append(df_train[class_name][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,52):\n",
    "    data_path = df_val[column][i]\n",
    "    \n",
    "    flair_path = os.path.join(input_path,data_path,data_path+flair_format)\n",
    "    flair_image = nib.load(flair_path)\n",
    "    flair = flair_image.get_data()\n",
    "    flair[flair!=0] = ((((flair[flair!=0] - np.mean(flair[flair!=0]))/ np.std(flair[flair!=0]))+ 10)* 100).astype(dtype=np.int16)\n",
    "    val_flair.append(flair)\n",
    "    \n",
    "    t1_path = os.path.join(input_path,data_path,data_path+t1_format)\n",
    "    t1_image = nib.load(t1_path)\n",
    "    t1 = t1_image.get_data()\n",
    "    t1[t1!=0] = ((((t1[t1!=0] - np.mean(t1[t1!=0]))/ np.std(t1[t1!=0]))+ 10)* 100).astype(dtype=np.int16)\n",
    "    val_t1.append(t1)\n",
    "    \n",
    "    t1ce_path = os.path.join(input_path,data_path,data_path+t1ce_format)\n",
    "    t1ce_image = nib.load(t1ce_path)\n",
    "    t1ce = t1ce_image.get_data()\n",
    "    t1ce[t1ce!=0] = ((((t1ce[t1ce!=0] - np.mean(t1ce[t1ce!=0]))/ np.std(t1ce[t1ce!=0]))+ 10)* 100).astype(dtype=np.int16)\n",
    "    val_t1ce.append(t1ce)\n",
    "    \n",
    "    t2_path = os.path.join(input_path,data_path,data_path+t2_format)\n",
    "    t2_image = nib.load(t2_path)\n",
    "    t2 = t2_image.get_data()\n",
    "    t2[t2!=0] = ((((t2[t2!=0] - np.mean(t2[t2!=0]))/ np.std(t2[t2!=0]))+ 10)* 100).astype(dtype=np.int16)\n",
    "    val_t2.append(t2)\n",
    "    \n",
    "    val_class.append(df_val[class_name][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_class = []\n",
    "val_class = []\n",
    "\n",
    "for i in class_train:\n",
    "    if i == 'G':\n",
    "        train_class.append(1)\n",
    "    else:\n",
    "        train_class.append(0)\n",
    "\n",
    "for i in class_val:\n",
    "    if i == 'G':\n",
    "        val_class.append(1)\n",
    "    else:\n",
    "        val_class.append(0)\n",
    "\n",
    "train_labels = to_categorical(train_class)\n",
    "val_labels = to_categorical(val_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_flair = np.array(train_flair)\n",
    "val_flair = np.array(val_flair)\n",
    "train_t1 = np.array(train_t1)\n",
    "val_t1 = np.array(val_t1)\n",
    "train_t1ce = np.array(train_t1ce)\n",
    "val_t1ce = np.array(val_t1ce)\n",
    "train_t2 = np.array(train_t2)\n",
    "val_t2 = np.array(val_t2)\n",
    "\n",
    "train_flair = np.array(train_flair).reshape(208, 80, 96, 64, 1)\n",
    "val_flair = np.array(val_flair).reshape(52, 80, 96, 64, 1)\n",
    "train_t1 = np.array(train_t1).reshape(208, 80, 96, 64, 1)\n",
    "val_t1 = np.array(val_t1).reshape(52, 80, 96, 64, 1)\n",
    "train_t1ce = np.array(train_t1ce).reshape(208, 80, 96, 64, 1)\n",
    "val_t1ce = np.array(val_t1ce).reshape(52, 80, 96, 64, 1)\n",
    "train_t2 = np.array(train_t2).reshape(208, 80, 96, 64, 1)\n",
    "val_t2 = np.array(val_t2).reshape(52, 80, 96, 64, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = Input(shape = (80, 96, 64, 1))\n",
    "\n",
    "conv1_1 = Conv3D(32, 3, activation = 'relu')(input_shape)\n",
    "conv1_2 = Conv3D(32, 3, activation = 'relu')(conv1_1)\n",
    "pool1_1 = MaxPooling3D(pool_size=(3,3,3))(conv1_2)\n",
    "conv1_3 = Conv3D(32, 3, activation = 'relu')(pool1_1)\n",
    "conv1_4 = Conv3D(32, 3, activation = 'relu')(conv1_3)\n",
    "pool1_2 = MaxPooling3D(pool_size=(3,3,3))(conv1_4)\n",
    "conv1_5 = Conv3D(32, 3, activation = 'relu')(pool1_2)\n",
    "conv1_6 = Conv3D(32, 3, activation = 'relu')(conv1_5)\n",
    "pool1_3 = MaxPooling3D(pool_size=(3,3,3))(conv1_6)\n",
    "flat1 = Flatten()(pool1_3)\n",
    "\n",
    "conv2_1 = Conv3D(32, 3, activation = 'relu')(input_shape)\n",
    "conv2_2 = Conv3D(32, 3, activation = 'relu')(conv2_1)\n",
    "pool2_1 = MaxPooling3D(pool_size=(3,3,3))(conv2_2)\n",
    "conv2_3 = Conv3D(32, 3, activation = 'relu')(pool2_1)\n",
    "conv2_4 = Conv3D(32, 3, activation = 'relu')(conv2_3)\n",
    "pool2_2 = MaxPooling3D(pool_size=(3,3,3))(conv2_4)\n",
    "conv2_5 = Conv3D(32, 3, activation = 'relu')(pool2_2)\n",
    "conv2_6 = Conv3D(32, 3, activation = 'relu')(conv2_5)\n",
    "pool2_3 = MaxPooling3D(pool_size=(3,3,3))(conv2_6)\n",
    "flat2 = Flatten()(pool2_3)\n",
    "\n",
    "conv3_1 = Conv3D(32, 3, activation = 'relu')(input_shape)\n",
    "conv3_2 = Conv3D(32, 3, activation = 'relu')(conv3_1)\n",
    "pool3_1 = MaxPooling3D(pool_size=(3,3,3))(conv3_2)\n",
    "conv3_3 = Conv3D(32, 3, activation = 'relu')(pool3_1)\n",
    "conv3_4 = Conv3D(32, 3, activation = 'relu')(conv3_3)\n",
    "pool3_2 = MaxPooling3D(pool_size=(3,3,3))(conv3_4)\n",
    "conv3_5 = Conv3D(32, 3, activation = 'relu')(pool3_2)\n",
    "conv3_6 = Conv3D(32, 3, activation = 'relu')(conv3_5)\n",
    "pool3_3 = MaxPooling3D(pool_size=(3,3,3))(conv3_6)\n",
    "flat3 = Flatten()(pool3_3)\n",
    "\n",
    "conv4_1 = Conv3D(32, 3, activation = 'relu')(input_shape)\n",
    "conv4_2 = Conv3D(32, 3, activation = 'relu')(conv4_1)\n",
    "pool4_1 = MaxPooling3D(pool_size=(3,3,3))(conv4_2)\n",
    "conv4_3 = Conv3D(32, 3, activation = 'relu')(pool4_1)\n",
    "conv4_4 = Conv3D(32, 3, activation = 'relu')(conv4_3)\n",
    "pool4_2 = MaxPooling3D(pool_size=(3,3,3))(conv4_4)\n",
    "conv4_5 = Conv3D(32, 3, activation = 'relu')(pool4_2)\n",
    "conv4_6 = Conv3D(32, 3, activation = 'relu')(conv4_5)\n",
    "pool4_3 = MaxPooling3D(pool_size=(3,3,3))(conv4_6)\n",
    "flat4 = Flatten()(pool4_3)\n",
    "\n",
    "merge = concatenate([flat1, flat2, flat3, flat4])\n",
    "\n",
    "hidden = Dense(128, activation = 'relu')(merge)\n",
    "dropout = Dropout(0.5)(hidden)\n",
    "output = Dense(3, activation = 'softmax')(dropout)\n",
    "\n",
    "model = Model(inputs = input_shape, outputs = output)\n",
    "\n",
    "model.compile(\n",
    "    loss = 'categorical_crossentropy',\n",
    "    optimizer = Adam(lr = 0.000001),\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timee = time.time()\n",
    "\n",
    "history = model.fit([train_flair, train_t1, train_t1ce, train_t2], train_labels, batch_size = 20, epochs = 20)\n",
    "\n",
    "print(time.time()-timee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('/content/drive/My Drive/Upenn_Data/Models/2class_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate([val_flair, val_t1, val_t1ce, val_t2], val_labels, batch_size =5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Training')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Accuracy', 'Loss'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
